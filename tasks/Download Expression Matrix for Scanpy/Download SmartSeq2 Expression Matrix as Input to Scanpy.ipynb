{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SmartSeq2 Expression Matrix as an Input to Scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I want to get a SmartSeq2 expression matrix that I can analyze using scanpy. How can I go about finding something like this using the DSS API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hca.dss\n",
    "client = hca.dss.DSSClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, first things first: We're going to need to search for a `.results` file. This file should contain what we need to put together an expression matrix.\n",
    "\n",
    "Here's our ElasticSearch query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"files.file_json.files.content.file_core.file_format\": \"results\" # It needs to have a\n",
    "                    }                                                                    # results file...\n",
    "                },\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"manifest.version\": {\n",
    "                            \"gte\": \"2018-07-12T100000.000000Z\" # ...and preferably not be too old, either.\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query looks for bundles that satisfy a *bool*ean condition consisting of two checks, both of which *must* be true. The *match* check looks for the `file_format` field and returns true if its value matches the string 'results'. The second check, *range*, returns true if the bundle's `manifest.version` has a value greater than or equal to 7/12/18. In short, __this query will find bundles that contain a `.results` file and are newer than July 12, 2018.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Prior to HCA's official release, there are no analysis bundles in `production`. Instead, you will need to look under `integration` in order to find one. To do this, set `client.host`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.host = 'https://dss.integration.data.humancellatlas.org/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's execute the search. Since the `files` section of the bundle is pretty long, I'll only print the portion containing a results file (in this case, the 28th file in the bundle). If you want, you can always print the entire bundle to get a better picture of where the file is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": {\n",
      "        \"describedBy\": \"http://schema.integration.data.humancellatlas.org/type/file/5.2.1/analysis_file\",\n",
      "        \"file_core\": {\n",
      "            \"file_format\": \"results\",\n",
      "            \"file_name\": \"4ee53206-80cd-4144-8c75-b62399a7ae99_rsem.genes.results\"\n",
      "        },\n",
      "        \"schema_type\": \"file\"\n",
      "    },\n",
      "    \"hca_ingest\": {\n",
      "        \"document_id\": \"153552fc-d65f-41af-afa6-3fa85a87d24f\",\n",
      "        \"submissionDate\": \"2018-07-25T21:39:23.972Z\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Print part of a recent analysis bundle with a results file\n",
    "\n",
    "bundles = client.post_search(es_query=query, replica='aws', output_format='raw')\n",
    "print(json.dumps(bundles['results'][0]['metadata']['files']['file_json']['files'][27], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! It looks like we've found a file uuid we can use: `153552fc-d65f-41af-afa6-3fa85a87d24f`. Let's save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7629174"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = client.get_file(replica='aws', uuid='153552fc-d65f-41af-afa6-3fa85a87d24f')\n",
    "open('matrix.results', 'w').write(results.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what our file, `matrix.results`, looks like. I've truncated the output so it doesn't take up too much room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_id\ttranscript_id(s)\tlength\teffective_length\texpected_count\tTPM\tFPKM\tposterior_mean_count\tposterior_standard_deviation_of_count\tpme_TPM\tpme_FPKM\n",
      "ENSG00000000003.14\tENST00000373020.8,ENST00000494424.1,ENST00000496771.5,ENST00000612152.4,ENST00000614008.4\t1749.40\t1541.80\t0.00\t0.00\t0.00\t0.00\t0.00\t2.02\t23.44\n",
      "ENSG00000000005.5\tENST00000373031.4,ENST00000485971.1\t940.50\t732.90\t0.00\t0.00\t0.00\t0.00\t0.00\t1.54\t17.88\n",
      "ENSG00000000419.12\tENST00000371582.8,ENST00000371584.8,ENST00000371588.9,ENST00000413082.1,ENST00000466152.5,ENST00000494752.1\t977.83\t770.24\t0.00\t0.00\t0.00\t0.00\t0.00\t3.32\t38.56\n",
      "ENSG00000000457.13\tENST00000367770.5,ENST00000367771.10,ENST00000367772.8,ENST00000423670.1,ENST00000470238.1\t3197.00\t2989.40\t0.00\t0.00\t0.00\t0.00\t0.00\t0.86\t9.99\n",
      "ENSG00000000460.16\tENST00000286031.10,ENST00000359326.8,ENST00000413811.3,ENST00000459772.5,ENST00000466580.6,ENST0000047\n"
     ]
    }
   ],
   "source": [
    "print(open('matrix.results', 'r').read()[:873])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our matrix, however, we might only want _some_ of these values. In my case, suppose I only want the `gene_id` and `TPM` values. We can extract these values easily using Python's `csv` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Take the data we want out of the results file and store it into a tsv file\n",
    "\n",
    "with open('matrix.results', 'r') as infile, open('matrix.tsv', 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=['gene_id', 'TPM'], delimiter='\\t')\n",
    "    for row in reader:\n",
    "        writer.writerow({'gene_id': row['gene_id'], 'TPM': row['TPM']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new file, `matrix.tsv`, looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSG00000000003.14\t0.00\n",
      "ENSG00000000005.5\t0.00\n",
      "ENSG00000000419.12\t0.00\n",
      "ENSG00000000457.13\t0.00\n",
      "ENSG00000000460.16\t0.00\n",
      "ENSG00000000938.12\t0.00\n",
      "ENSG00000000971.15\t0.00\n",
      "ENSG00000001036.13\t0.00\n",
      "ENSG00000001084.10\t0.00\n"
     ]
    }
   ],
   "source": [
    "print(open('matrix.tsv', 'r').read()[:214])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a file containing what we want, we can transpose it and read it into scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy.api as sc\n",
    "\n",
    "adata = sc.read_csv(filename='matrix.tsv', delimiter='\\t').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we know that everything worked? Let's print our AnnData object (truncating the output again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1 × 58347 \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n"
     ]
    }
   ],
   "source": [
    "print(adata)\n",
    "for i in range(0, 153):\n",
    "    print('{:<6}'.format('{:.1f}'.format(adata.X[i])), end='' if (i + 1) % 17 != 0 else '\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to make it easier to see the relevant data in our matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.74 2289.43 1079.51 33.39 71.25 306.59 55.48 262.12 233.33 359.17 579.74 875.4 1571.24 7501.46 114659.92 347.55 76.15 1258.66 42.63 170.67 1384.1 2636.91 8210.16 23152.72 40069.76 15311.09 51841.59 988.92 8740.85 1786.69 13603.32 33274.64 314.7 1665.7 6726.94 12717.9 46112.46 10746.5 2619.5 637.16 21969.11 17856.29 794.83 23246.24 2372.67 78258.91 26619.13 109.81 8582.35 1111.28 1170.91 6920.93 161.06 250.58 171.18 126.3 20162.46 118.0 6422.18 774.58 9770.59 9643.0 3571.98 36718.99 45083.26 1618.13 18952.62 24666.38 1357.03 1071.54 694.25 652.7 1615.82 386.99 5256.2 867.7 17468.06 199.05 841.76 99981.39 15283.49 127.55 858.33 220.5 1144.79 1475.82 9094.49 6.09 35948.45 183.31 12083.88 1119.97 561.17 766.69 147.05 1427.83 3711.39 305.53 279.72 2907.42 105.23 "
     ]
    }
   ],
   "source": [
    "for i in range(len(adata.X)-1):\n",
    "    if adata.X[i] != 0:\n",
    "        print(adata.X[i], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have one AnnData object we can use with scanpy. __But what if we want a second one?__ Let's go through the steps again, this time with a different `.results` file. We can use the same query to get a bunch of analysis bundles, but this time get our `.results` file from the _second_ bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": {\n",
      "        \"describedBy\": \"https://schema.humancellatlas.org/type/file/5.2.1/analysis_file\",\n",
      "        \"file_core\": {\n",
      "            \"file_format\": \"results\",\n",
      "            \"file_name\": \"84b516d0-30e9-4693-9658-a63aecb48040_rsem.genes.results\"\n",
      "        },\n",
      "        \"schema_type\": \"file\"\n",
      "    },\n",
      "    \"hca_ingest\": {\n",
      "        \"document_id\": \"9ae45bb8-7130-4e06-a5af-87b587155034\",\n",
      "        \"submissionDate\": \"2018-07-25T21:10:58.516Z\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bundles = client.post_search(es_query=query, replica='aws', output_format='raw')\n",
    "print(json.dumps(bundles['results'][1]['metadata']['files']['file_json']['files'][27], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new uuid, we can get the `.results` file itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7629176"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = client.get_file(replica='aws', uuid='9ae45bb8-7130-4e06-a5af-87b587155034')\n",
    "open('matrix2.results', 'w').write(results2.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's take the data we want out of the results file and store it into a tsv file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matrix2.results', 'r') as infile, open('matrix2.tsv', 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=['gene_id', 'TPM'], delimiter='\\t')\n",
    "    for row in reader:\n",
    "        writer.writerow({'gene_id': row['gene_id'], 'TPM': row['TPM']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then create another AnnData object & print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1 × 58347 \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n"
     ]
    }
   ],
   "source": [
    "adata2 = sc.read_csv( filename='matrix.tsv', delimiter='\\t' ).transpose()\n",
    "\n",
    "print(adata2)\n",
    "for i in range(0, 153):\n",
    "    print( '{:<6}'.format('{:.1f}'.format(adata2.X[i])), end='' if (i + 1) % 17 != 0 else '\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've set up your two matrices in scanpy, you're ready to perform whatever analysis piques your interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
