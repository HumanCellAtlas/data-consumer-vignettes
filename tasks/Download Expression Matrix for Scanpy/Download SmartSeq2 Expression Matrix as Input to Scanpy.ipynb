{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SmartSeq2 Expression Matrix as an Input to Scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to ~/.config/hca/ and edit the config file\n",
    "2. Change https://dss.data.humancellatlas.org/v1/swagger.json to https://dss.integration.data.humancellatlas.org/v1/swagger.json\n",
    "3. Restart your computer\n",
    "4. Execute the following code to get an analysis bundle. For some reason, you can only view bundles from the current day in raw without getting an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import hca.dss, json\n",
    "client = hca.dss.DSSClient()\n",
    "\n",
    "# query = {\n",
    "#     \"query\": {\n",
    "#       \"bool\": {\n",
    "#         \"must\": [\n",
    "#           {\n",
    "#             \"match\": {\n",
    "#               \"files.process_json.processes.content.protocol_type.text\": \"analysis\"\n",
    "#             }\n",
    "#           },\n",
    "#           {\n",
    "#             \"range\": {\n",
    "#               \"manifest.version\": {\n",
    "#                 \"gte\": \"2018-07-12T100000.000000Z\"\n",
    "#               }\n",
    "#             }\n",
    "#           }\n",
    "#         ]\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "      \"bool\": {\n",
    "        \"must\": [\n",
    "          {\n",
    "            \"query_string\": {\n",
    "              \"fields\": [\n",
    "                \"*uuid\"\n",
    "              ],\n",
    "              \"query\": \"703fcaa2-92f5-4f62-9173-adbec7c355c8\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"range\": {\n",
    "              \"manifest.version\": {\n",
    "                \"gte\": \"2018-07-12T100000.000000Z\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "# Print all recent analysis bundles\n",
    "# for bundle in client.post_search.iterate(es_query=query, replica='aws', output_format='raw'):\n",
    "#     print(json.dumps(bundle, indent=4, sort_keys=True))\n",
    "#     break\n",
    "\n",
    "# Get the expression matrix\n",
    "#file = client.get_file(replica='aws', uuid='703fcaa2-92f5-4f62-9173-adbec7c355c8')\n",
    "file = client.get_file(replica='aws', uuid='c95ba558-b750-449d-97fc-eb367701a3a4')\n",
    "\n",
    "with open('out.txt', 'w') as outfile:\n",
    "    outfile.write(file.decode(\"utf-8\"))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find bundles by searching their metadata with an Elasticsearch query\n",
      "\n",
      "\n",
      "\n",
      ".. admonition:: Pagination\n",
      "\n",
      " This method supports pagination. Use ``DSSClient.post_search.iterate(**kwargs)`` to create a generator that\n",
      " yields all results, making multiple requests over the wire if necessary:\n",
      "\n",
      " .. code-block:: python\n",
      "\n",
      "   for result in DSSClient.post_search.iterate(**kwargs):\n",
      "       ...\n",
      "\n",
      " The keyword arguments for ``DSSClient.post_search.iterate()`` are identical to the arguments for\n",
      " ``DSSClient.post_search()`` listed here.\n",
      ":param es_query:  Elasticsearch query \n",
      ":type es_query: typing.Mapping\n",
      ":param output_format:  Specifies the output format. The default format, ``summary``, is a list of UUIDs for bundles that match the query. Set this parameter to ``raw`` to get the verbatim JSON metadata for bundles that match the query. \n",
      ":type output_format: typing.Union[str, NoneType]\n",
      ":param replica:  Replica to search. \n",
      ":type replica: <class 'str'>\n",
      ":param per_page:  Max number of results to return per page. \n",
      ":type per_page: typing.Union[str, NoneType]\n",
      ":param search_after:  **Search-After-Context**. An internal state pointer parameter for use with pagination. This parameter is referenced by the ``Link`` header as described in the \"Pagination\" section. The API client should not need to set this parameter directly; it should instead directly fetch the URL given in the ``Link`` header. \n",
      ":type search_after: typing.Union[str, NoneType]\n",
      "\n",
      "\n",
      "\n",
      "Accepts Elasticsearch JSON query and returns matching bundle identifiers\n",
      "\n",
      "**Pagination**\n",
      "\n",
      "The DSS API supports pagination in a manner consistent with the\n",
      "`GitHub API <https://developer.github.com/v3/guides/traversing-with-pagination/>`_, which is based on\n",
      "`RFC 5988 <https://tools.ietf.org/html/rfc5988>`_. When the results of an API call exceed the page size\n",
      "specified, the HTTP response will contain a ``Link`` header of the following form:\n",
      "``Link: <https://dss.data.humancellatlas.org/v1/search?replica=aws&per_page=100&search_after=123>; rel=\"next\"``.\n",
      "The URL in the header refers to the next page of the results to be fetched; if no ``Link rel=\"next\"`` URL is\n",
      "included, then all results have been fetched. The client should recognize and parse the ``Link`` header\n",
      "appropriately according to RFC 5988, and retrieve the next page if requested by the user, or if all results\n",
      "are being retrieved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(client.post_search.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Decompress the .results file (our expression matrix) and write it to a .tsv file\n",
    "6. Input the expression matrix to scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('out.txt', newline='') as tsvfile:\n",
    "    reader = csv.DictReader(tsvfile, delimiter='\\t')\n",
    "    c = 0\n",
    "    for row in reader:\n",
    "        print(row['pme_FPKM'])\n",
    "        c +=1\n",
    "        if c > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ENST00000373020.8,ENST00000494424.1,ENST00000496771.5,ENST00000612152.4,ENST00000614008.4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ba79169b4d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(sc.read_text.__doc__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0madata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test_exp_mtr.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_column_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#adata = anndata.AnnData(filename='expression_matrix.tsv', dtype=str)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anndata\\readwrite\\read.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filename, delimiter, first_column_names, dtype)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mNumpy\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mread_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_column_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anndata\\readwrite\\read.py\u001b[0m in \u001b[0;36mread_text\u001b[1;34m(filename, delimiter, first_column_names, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_read_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_column_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anndata\\readwrite\\read.py\u001b[0m in \u001b[0;36m_read_text\u001b[1;34m(f, delimiter, first_column_names, dtype)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mfirst_column_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mrow_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ENST00000373020.8,ENST00000494424.1,ENST00000496771.5,ENST00000612152.4,ENST00000614008.4'"
     ]
    }
   ],
   "source": [
    "import scanpy.api as sc\n",
    "\n",
    "# print(sc.read_csv.__doc__)\n",
    "# print(sc.read.__doc__)\n",
    "# print(sc.read_text.__doc__)\n",
    "\n",
    "adata = sc.read_csv(filename='test_exp_mtr.tsv', delimiter='\\t', first_column_names=True)\n",
    "#adata = anndata.AnnData(filename='expression_matrix.tsv', dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
